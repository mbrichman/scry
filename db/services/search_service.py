"""
Unified SearchService with hybrid ranking combining:
1. Lexical Full-Text Search (PostgreSQL FTS)
2. Semantic Vector Search (pgvector)
3. Hybrid ranking that blends both approaches
4. Query expansion and result optimization
"""

import logging
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional, Tuple
from uuid import UUID
from dataclasses import dataclass
import math

from db.repositories.unit_of_work import get_unit_of_work
from db.workers.embedding_worker import EmbeddingGenerator
from config.synonyms import SEARCH_SYNONYMS

logger = logging.getLogger(__name__)


@dataclass
class SearchConfig:
    """Configuration for search behavior and ranking weights."""
    # Ranking weights (must sum to 1.0)
    # Changed from 0.6/0.4 to 0.4/0.6 - FTS is more reliable for exact queries
    vector_weight: float = 0.4
    fts_weight: float = 0.6

    # Search thresholds
    vector_similarity_threshold: float = 0.2  # Minimum cosine similarity
    fts_rank_threshold: float = 0.01  # Minimum FTS rank

    # Result limits
    max_results: int = 50
    max_fts_results: int = 100
    max_vector_results: int = 100
    initial_result_limit: int = 20  # Show top N results by default

    # Quality cutoff
    enable_quality_cutoff: bool = True
    quality_drop_threshold: float = 0.5  # Stop if score drops to 50% of top score

    # Query processing
    enable_query_expansion: bool = True
    enable_typo_tolerance: bool = True
    typo_tolerance_threshold: float = 0.15  # Minimum trigram similarity for fuzzy matches
    typo_fallback_min_results: int = 3  # If FTS returns fewer results, try fuzzy matching

    # Phrase matching (Phase 1 improvements)
    enable_phrase_matching: bool = True  # Use phraseto_tsquery for multi-word queries
    phrase_boost: float = 2.0  # Boost multiplier for phrase matches

    # Exact substring boost (Phase 1 improvements)
    enable_exact_substring_boost: bool = True  # Boost results containing exact query
    exact_substring_boost: float = 1.5  # Multiplier for exact substring matches

    # Recency boost - favor recent conversations in search
    enable_recency_boost: bool = True  # Boost newer conversations
    recency_weight: float = 0.15  # 15% of score comes from recency
    recency_full_boost_days: int = 30  # Full recency score for last 30 days
    recency_half_boost_days: int = 60  # 75% score for 30-60 days
    recency_quarter_boost_days: int = 180  # 50% score for 60-180 days
    # Older than 180 days gets 25% recency score

    def __post_init__(self):
        """Validate configuration."""
        if abs(self.vector_weight + self.fts_weight - 1.0) > 0.01:
            raise ValueError("vector_weight + fts_weight must equal 1.0")


@dataclass 
class SearchResult:
    """Unified search result with metadata."""
    message_id: str
    conversation_id: str
    role: str
    content: str
    created_at: str
    conversation_title: str
    
    # Scores
    combined_score: float
    vector_score: Optional[float] = None
    fts_score: Optional[float] = None
    
    # Additional metadata
    similarity: Optional[float] = None
    fts_rank: Optional[float] = None
    distance: Optional[float] = None
    source: str = "hybrid"
    
    def to_legacy_format(self) -> Dict[str, Any]:
        """Convert to legacy API format for compatibility."""
        # Format timestamp for legacy compatibility
        timestamp_str = self.created_at
        
        # Build document content in legacy format
        if self.role == 'user':
            document_content = f"**You said** *(on {timestamp_str})*:\n\n{self.content}"
        elif self.role == 'assistant':
            document_content = f"**Assistant said** *(on {timestamp_str})*:\n\n{self.content}"
        elif self.role == 'system':
            document_content = f"**System** *(on {timestamp_str})*:\n\n{self.content}"
        else:
            document_content = f"**{self.role.capitalize()}** *(on {timestamp_str})*:\n\n{self.content}"
        
        return {
            'id': self.conversation_id,  # Use conversation ID for API compatibility
            'document': document_content,
            'metadata': {
                'title': self.conversation_title,
                'source': self.source,
                'message_count': 1,  # Single message
                'earliest_ts': self.created_at,
                'latest_ts': self.created_at,
                'conversation_id': self.conversation_id,
                'message_id': self.message_id,
                'role': self.role,
                'combined_score': self.combined_score,
                'vector_score': self.vector_score,
                'fts_score': self.fts_score,
                'similarity': self.similarity,
                'fts_rank': self.fts_rank,
                'distance': self.distance
            }
        }


class SearchService:
    """
    Unified search service that combines FTS and vector search with hybrid ranking.
    """
    
    def __init__(self, config: Optional[SearchConfig] = None):
        self.config = config or SearchConfig()
        self._embedding_generator = None
        
    @property
    def embedding_generator(self) -> EmbeddingGenerator:
        """Lazy load the embedding generator."""
        if self._embedding_generator is None:
            self._embedding_generator = EmbeddingGenerator()
        return self._embedding_generator
    
    def search(self,
               query: str,
               limit: Optional[int] = None,
               conversation_id: Optional[UUID] = None,
               config_override: Optional[SearchConfig] = None,
               show_all: bool = False) -> Tuple[List[SearchResult], Dict[str, Any]]:
        """
        Perform hybrid search combining FTS and vector similarity.

        Args:
            query: Search query string
            limit: Maximum number of results
            conversation_id: Optional conversation filter
            config_override: Override default search configuration
            show_all: If True, bypass quality cutoff and show all results

        Returns:
            Tuple of (results, metadata) where metadata contains:
            - total_results: Total number of results before cutoff
            - truncated: Whether results were cut off for quality
            - cutoff_index: Index where quality cutoff was applied
        """
        config = config_override or self.config
        limit = limit or config.max_results

        logger.info(f"ðŸ” Hybrid search: '{query[:50]}...' (limit: {limit}, show_all: {show_all})")

        try:
            # Generate query embedding for vector search
            query_embedding = self._generate_query_embedding(query)

            with get_unit_of_work() as uow:
                # Perform both search types in parallel
                fts_results = self._fts_search(uow, query, config, conversation_id)
                vector_results = self._vector_search(uow, query_embedding, config, conversation_id)

                # Combine and rank results
                combined_results = self._combine_and_rank_results(
                    fts_results, vector_results, config, query
                )

                # Apply quality cutoff if enabled and not showing all
                metadata = {
                    'total_results': len(combined_results),
                    'truncated': False,
                    'cutoff_index': None
                }

                if not show_all and config.enable_quality_cutoff and len(combined_results) > config.initial_result_limit:
                    cutoff_index = self._find_quality_cutoff(combined_results, config)
                    if cutoff_index and cutoff_index < len(combined_results):
                        metadata['truncated'] = True
                        metadata['cutoff_index'] = cutoff_index
                        combined_results = combined_results[:cutoff_index]
                        logger.info(f"ðŸ“Š Quality cutoff applied at index {cutoff_index}")

                # Apply final limit
                final_results = combined_results[:limit]

                logger.info(f"âœ… Search complete: {len(fts_results)} FTS + {len(vector_results)} vector â†’ {len(final_results)} final (total: {metadata['total_results']})")

                return final_results, metadata

        except Exception as e:
            logger.error(f"âŒ Search failed: {e}")
            raise
    
    def search_fts_only(self,
                        query: str,
                        limit: Optional[int] = None,
                        conversation_id: Optional[UUID] = None,
                        show_all: bool = False) -> Tuple[List[SearchResult], Dict[str, Any]]:
        """Perform full-text search only with quality cutoff."""
        limit = limit or self.config.max_results

        logger.info(f"ðŸ“ FTS-only search: '{query[:50]}...' (show_all: {show_all})")

        with get_unit_of_work() as uow:
            fts_results = self._fts_search(uow, query, self.config, conversation_id)

            # Convert to SearchResult format
            search_results = []
            for result in fts_results:
                meta = result['metadata']
                search_results.append(SearchResult(
                    message_id=meta['message_id'],
                    conversation_id=meta['conversation_id'],
                    role=meta['role'],
                    content=self._extract_content_from_document(result['document']),
                    created_at=meta['earliest_ts'],
                    conversation_title=meta['title'],
                    combined_score=meta.get('rank', 0),
                    fts_score=meta.get('rank', 0),
                    fts_rank=meta.get('rank', 0),
                    source='fts'
                ))

            # Apply quality cutoff if enabled and not showing all
            metadata = {
                'total_results': len(search_results),
                'truncated': False,
                'cutoff_index': None
            }

            if not show_all and self.config.enable_quality_cutoff and len(search_results) > self.config.initial_result_limit:
                cutoff_index = self._find_quality_cutoff(search_results, self.config)
                if cutoff_index and cutoff_index < len(search_results):
                    metadata['truncated'] = True
                    metadata['cutoff_index'] = cutoff_index
                    search_results = search_results[:cutoff_index]
                    logger.info(f"ðŸ“Š FTS quality cutoff applied at index {cutoff_index}")

            # Apply final limit
            final_results = search_results[:limit]

            logger.info(f"âœ… FTS search complete: {len(final_results)} results (total: {metadata['total_results']})")
            return final_results, metadata
    
    def search_vector_only(self, 
                          query: str, 
                          limit: Optional[int] = None,
                          conversation_id: Optional[UUID] = None) -> List[SearchResult]:
        """Perform vector search only."""
        limit = limit or self.config.max_results
        
        logger.info(f"ðŸŽ¯ Vector-only search: '{query[:50]}...'")
        
        try:
            query_embedding = self._generate_query_embedding(query)
            
            with get_unit_of_work() as uow:
                vector_results = self._vector_search(uow, query_embedding, self.config, conversation_id)
                
                # Convert to SearchResult format
                search_results = []
                for result in vector_results[:limit]:
                    meta = result['metadata']
                    search_results.append(SearchResult(
                        message_id=meta['message_id'],
                        conversation_id=meta['conversation_id'],
                        role=meta['role'],
                        content=self._extract_content_from_document(result['document']),
                        created_at=meta['earliest_ts'],
                        conversation_title=meta['title'],
                        combined_score=meta.get('similarity', 0),
                        vector_score=meta.get('similarity', 0),
                        similarity=meta.get('similarity', 0),
                        distance=meta.get('distance', 0),
                        source='vector'
                    ))
                
                logger.info(f"âœ… Vector search complete: {len(search_results)} results")
                return search_results
                
        except Exception as e:
            logger.error(f"âŒ Vector search failed: {e}")
            # Fallback to FTS if vector search fails
            logger.info("ðŸ”„ Falling back to FTS search")
            return self.search_fts_only(query, limit, conversation_id)
    
    def search_similar_to_message(self, 
                                 message_id: UUID, 
                                 limit: Optional[int] = None,
                                 conversation_id: Optional[UUID] = None) -> List[SearchResult]:
        """Find messages similar to a given message using vector search."""
        limit = limit or self.config.max_results
        
        logger.info(f"ðŸ”— Similar message search: {message_id}")
        
        with get_unit_of_work() as uow:
            # Get the source message's embedding
            source_embedding = uow.embeddings.get_by_message_id(message_id)
            if not source_embedding:
                logger.warning(f"No embedding found for message {message_id}")
                return []
            
            # Perform vector search using the source embedding
            vector_results = uow.embeddings.search_similar(
                query_embedding=source_embedding.embedding,
                limit=limit + 1,  # +1 because source message will be included
                distance_threshold=1.0 - self.config.vector_similarity_threshold,
                conversation_id=conversation_id
            )
            
            # Filter out the source message itself
            filtered_results = [r for r in vector_results if r['metadata']['message_id'] != str(message_id)]
            
            # Convert to SearchResult format
            search_results = []
            for result in filtered_results[:limit]:
                meta = result['metadata']
                search_results.append(SearchResult(
                    message_id=meta['message_id'],
                    conversation_id=meta['conversation_id'],
                    role=meta['role'],
                    content=self._extract_content_from_document(result['document']),
                    created_at=meta['earliest_ts'],
                    conversation_title=meta['title'],
                    combined_score=meta.get('similarity', 0),
                    vector_score=meta.get('similarity', 0),
                    similarity=meta.get('similarity', 0),
                    distance=meta.get('distance', 0),
                    source='similar'
                ))
            
            logger.info(f"âœ… Similar search complete: {len(search_results)} results")
            return search_results
    
    def _generate_query_embedding(self, query: str) -> List[float]:
        """Generate embedding for search query."""
        return self.embedding_generator.generate_embedding(query)
    
    def _fts_search(self, uow, query: str, config: SearchConfig, conversation_id: Optional[UUID]) -> List[Dict[str, Any]]:
        """Perform full-text search with phrase matching and typo tolerance."""
        # Expand query if enabled
        if config.enable_query_expansion:
            expanded_query = self._expand_query(query)
        else:
            expanded_query = query

        # Use phrase matching for multi-word queries if enabled
        if config.enable_phrase_matching and len(query.strip().split()) >= 2:
            # Use phrase-aware search (boosts exact phrase matches)
            results = uow.messages.search_full_text_phrase(
                query=query,  # Use original query for phrase matching
                limit=config.max_fts_results,
                conversation_id=conversation_id,
                phrase_boost=config.phrase_boost
            )
            logger.debug(f"ðŸ“ Using phrase matching for multi-word query")
        else:
            # Standard FTS for single words or when phrase matching disabled
            results = uow.messages.search_full_text(
                query=expanded_query,
                limit=config.max_fts_results,
                conversation_id=conversation_id
            )

        # Filter by rank threshold
        filtered_results = [
            r for r in results
            if r['metadata'].get('rank', 0) >= config.fts_rank_threshold
        ]

        # If typo tolerance is enabled and we have few or no results, try fuzzy matching
        if (config.enable_typo_tolerance and
            len(filtered_results) < config.typo_fallback_min_results and
            len(query.strip()) >= 3):  # Only for queries with 3+ characters

            logger.info(f"ðŸ”¤ FTS returned {len(filtered_results)} results, trying fuzzy matching for '{query}'")

            # Try fuzzy matching with trigrams
            fuzzy_results = self._fuzzy_search(uow, query, config, conversation_id)

            # Merge results, avoiding duplicates
            existing_ids = {r['metadata']['message_id'] for r in filtered_results}
            for fuzzy_result in fuzzy_results:
                if fuzzy_result['metadata']['message_id'] not in existing_ids:
                    # Convert similarity to rank for consistency
                    fuzzy_result['metadata']['rank'] = fuzzy_result['metadata'].pop('similarity', 0)
                    fuzzy_result['metadata']['fuzzy_match'] = True
                    filtered_results.append(fuzzy_result)

            logger.debug(f"FTS+Fuzzy: {len(filtered_results)} total results")

        logger.debug(f"FTS: {len(results)} raw â†’ {len(filtered_results)} after threshold/fuzzy")
        return filtered_results
    
    def _vector_search(self, uow, query_embedding: List[float], config: SearchConfig, conversation_id: Optional[UUID]) -> List[Dict[str, Any]]:
        """Perform vector similarity search."""
        distance_threshold = 1.0 - config.vector_similarity_threshold

        results = uow.embeddings.search_similar(
            query_embedding=query_embedding,
            limit=config.max_vector_results,
            distance_threshold=distance_threshold,
            conversation_id=conversation_id
        )

        # Filter by similarity threshold
        filtered_results = [
            r for r in results
            if r['metadata'].get('similarity', 0) >= config.vector_similarity_threshold
        ]

        logger.debug(f"Vector: {len(results)} raw â†’ {len(filtered_results)} after threshold")
        return filtered_results

    def _fuzzy_search(self, uow, query: str, config: SearchConfig, conversation_id: Optional[UUID]) -> List[Dict[str, Any]]:
        """
        Perform fuzzy text search using trigram similarity.
        This helps catch typos and misspellings.
        """
        try:
            results = uow.messages.search_trigram(
                query=query,
                limit=config.max_fts_results,
                similarity_threshold=config.typo_tolerance_threshold
            )

            logger.debug(f"Fuzzy search: found {len(results)} results with similarity >= {config.typo_tolerance_threshold}")
            return results

        except Exception as e:
            # If trigram extension is not available, log and return empty
            logger.warning(f"Fuzzy search failed (pg_trgm may not be installed): {e}")
            return []

    def _find_quality_cutoff(self, results: List[SearchResult], config: SearchConfig) -> Optional[int]:
        """
        Find the index where result quality drops off significantly.

        Returns the index after which results should be hidden by default,
        or None if no cutoff should be applied.
        """
        if len(results) <= config.initial_result_limit:
            return None

        # Get the top score as reference
        if not results or results[0].combined_score == 0:
            return config.initial_result_limit

        top_score = results[0].combined_score
        threshold_score = top_score * config.quality_drop_threshold

        # Find where score drops below threshold, but not before initial_result_limit
        for i in range(config.initial_result_limit, len(results)):
            if results[i].combined_score < threshold_score:
                logger.debug(f"Quality drop detected at index {i}: score {results[i].combined_score:.3f} < threshold {threshold_score:.3f}")
                return i

        # No significant drop found, use initial limit
        return config.initial_result_limit
    
    def _combine_and_rank_results(self,
                                 fts_results: List[Dict[str, Any]],
                                 vector_results: List[Dict[str, Any]],
                                 config: SearchConfig,
                                 query: str = "") -> List[SearchResult]:
        """Combine FTS and vector results with hybrid ranking and exact substring boost."""

        # Index results by message_id for merging
        fts_by_id = {r['metadata']['message_id']: r for r in fts_results}
        vector_by_id = {r['metadata']['message_id']: r for r in vector_results}

        # Get all unique message IDs
        all_message_ids = set(fts_by_id.keys()) | set(vector_by_id.keys())

        # Prepare for exact substring matching
        query_lower = query.lower().strip() if query else ""
        exact_boost_applied = 0

        combined_results = []

        for message_id in all_message_ids:
            fts_result = fts_by_id.get(message_id)
            vector_result = vector_by_id.get(message_id)

            # Extract scores (normalize to 0-1 range)
            fts_score = 0.0
            vector_score = 0.0

            if fts_result:
                fts_rank = fts_result['metadata'].get('rank', 0)
                fts_score = self._normalize_fts_score(fts_rank)

            if vector_result:
                similarity = vector_result['metadata'].get('similarity', 0)
                vector_score = max(0, similarity)  # Similarity is already 0-1

            # Calculate combined score
            combined_score = (
                config.fts_weight * fts_score +
                config.vector_weight * vector_score
            )

            # Use the result with more complete data (prefer vector for content quality)
            base_result = vector_result or fts_result
            meta = base_result['metadata']
            content = self._extract_content_from_document(base_result['document'])

            # Apply exact substring boost if enabled
            if (config.enable_exact_substring_boost and
                query_lower and
                len(query_lower) >= 3 and
                query_lower in content.lower()):
                combined_score *= config.exact_substring_boost
                exact_boost_applied += 1

            # Apply recency boost if enabled
            if config.enable_recency_boost:
                recency_score = self._calculate_recency_score(meta['earliest_ts'], config)
                # Blend: (1 - recency_weight) * relevance + recency_weight * recency
                combined_score = (
                    (1 - config.recency_weight) * combined_score +
                    config.recency_weight * recency_score
                )

            # Create unified search result
            search_result = SearchResult(
                message_id=meta['message_id'],
                conversation_id=meta['conversation_id'],
                role=meta['role'],
                content=content,
                created_at=meta['earliest_ts'],
                conversation_title=meta['title'],
                combined_score=combined_score,
                vector_score=vector_score if vector_result else None,
                fts_score=fts_score if fts_result else None,
                similarity=vector_result['metadata'].get('similarity') if vector_result else None,
                fts_rank=fts_result['metadata'].get('rank') if fts_result else None,
                distance=vector_result['metadata'].get('distance') if vector_result else None,
                source='hybrid'
            )

            combined_results.append(search_result)

        # Sort by combined score (descending)
        combined_results.sort(key=lambda x: x.combined_score, reverse=True)

        if exact_boost_applied > 0:
            logger.debug(f"ðŸŽ¯ Exact substring boost applied to {exact_boost_applied} results")
        logger.debug(f"Combined: {len(all_message_ids)} unique messages")
        return combined_results
    
    def _normalize_fts_score(self, fts_rank: float) -> float:
        """Normalize FTS rank to 0-1 scale."""
        # PostgreSQL ts_rank typically returns values between 0 and 1
        # But can be higher, so we use a logarithmic normalization
        if fts_rank <= 0:
            return 0.0

        # Use log normalization to handle wide range of FTS scores
        normalized = math.log(1 + fts_rank) / math.log(2)  # log2(1 + rank)
        return min(1.0, normalized)

    def _calculate_recency_score(self, created_at: str, config: SearchConfig) -> float:
        """
        Calculate recency score (0-1) based on age of content.

        Uses linear window decay:
        - Last 30 days: 1.0 (full score)
        - 30-60 days: 0.75
        - 60-180 days: 0.5
        - Older: 0.25
        """
        try:
            # Parse timestamp
            if isinstance(created_at, str):
                if 'T' in created_at:
                    dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                else:
                    dt = datetime.strptime(created_at, "%Y-%m-%d %H:%M:%S")
                    dt = dt.replace(tzinfo=timezone.utc)
            else:
                dt = created_at

            now = datetime.now(timezone.utc)
            age_days = (now - dt).days

            if age_days < 0:
                age_days = 0

            # Linear window decay
            if age_days <= config.recency_full_boost_days:
                return 1.0
            elif age_days <= config.recency_half_boost_days:
                return 0.75
            elif age_days <= config.recency_quarter_boost_days:
                return 0.5
            else:
                return 0.25

        except Exception:
            return 0.5  # Default to middle score on parse error

    def _expand_query(self, query: str) -> str:
        """Expand query with synonyms and related terms."""
        # Simple query expansion - in production, use a proper synonym dictionary
        expanded_terms = []
        words = query.lower().split()
        
        # Use centralized synonym dictionary
        synonyms = SEARCH_SYNONYMS
        
        # First check for multi-word phrases in the original query
        query_lower = query.lower()
        matched_phrases = set()
        
        for phrase in synonyms.keys():
            if ' ' in phrase and phrase in query_lower:
                matched_phrases.add(phrase)
                # Add synonyms for matched phrase
                expanded_terms.extend(synonyms[phrase])
        
        # Then process individual words not part of matched phrases
        for word in words:
            # Skip if this word is part of a matched phrase
            if any(word in phrase.split() for phrase in matched_phrases):
                continue
            
            expanded_terms.append(word)
            if word in synonyms:
                expanded_terms.extend(synonyms[word][:1])  # Add one synonym
        
        # If no expansion occurred, return original query
        if not expanded_terms:
            return query
        
        # Join with OR for PostgreSQL FTS
        # Quote multi-word terms for proper FTS matching
        formatted_terms = []
        for term in expanded_terms:
            if ' ' in term:
                # For phrases, use proper FTS syntax
                formatted_terms.append(term.replace(' ', ' & '))
            else:
                formatted_terms.append(term)
        
        expanded_query = ' | '.join(formatted_terms) if len(expanded_terms) > 0 else query
        
        logger.debug(f"Query expansion: '{query}' â†’ '{expanded_query}'")
        return expanded_query
    
    def _extract_content_from_document(self, document: str) -> str:
        """Extract plain content from formatted document."""
        # Simple extraction - remove markdown-like formatting
        lines = document.split('\n')
        content_lines = []
        
        for line in lines:
            # Skip header lines with **...**
            if line.startswith('**') and '**' in line[2:]:
                continue
            # Skip empty lines
            if not line.strip():
                continue
            content_lines.append(line)
        
        return '\n'.join(content_lines)
    
    def get_query_suggestions(self, query: str, limit: int = 5) -> List[str]:
        """
        Get query suggestions for potentially misspelled queries.
        Returns a list of suggested corrections based on content similarity.
        """
        if len(query.strip()) < 3:
            return []

        try:
            with get_unit_of_work() as uow:
                # Use trigram similarity to find similar terms in the content
                # This is a simplified version - in production, you might want to:
                # 1. Build a dictionary of common terms from your corpus
                # 2. Use that dictionary for faster suggestion lookups
                sql_query = text("""
                    WITH words AS (
                        SELECT DISTINCT unnest(string_to_array(lower(content), ' ')) as word
                        FROM messages
                        WHERE length(unnest(string_to_array(lower(content), ' '))) >= 3
                        LIMIT 10000
                    )
                    SELECT word, similarity(word, :query) as sim
                    FROM words
                    WHERE similarity(word, :query) > 0.3
                    ORDER BY sim DESC
                    LIMIT :limit
                """)

                result = uow.session.execute(sql_query, {'query': query.lower(), 'limit': limit})
                suggestions = [row.word for row in result if row.word != query.lower()]

                logger.debug(f"Query suggestions for '{query}': {suggestions}")
                return suggestions

        except Exception as e:
            logger.warning(f"Failed to generate query suggestions: {e}")
            return []

    def get_search_stats(self) -> Dict[str, Any]:
        """Get search-related statistics."""
        with get_unit_of_work() as uow:
            # Get message and embedding counts
            message_stats = uow.messages.get_message_stats()

            # Get embedding coverage
            total_messages = message_stats['total_messages']
            embedded_messages = message_stats['embedded_messages']

            # Get job queue stats for embedding jobs
            embedding_job_stats = uow.jobs.get_embedding_job_stats()

            return {
                'total_messages': total_messages,
                'embedded_messages': embedded_messages,
                'embedding_coverage_percent': message_stats['embedding_coverage_percent'],
                'pending_embedding_jobs': embedding_job_stats['embedding_jobs_by_status'].get('pending', 0),
                'failed_embedding_jobs': embedding_job_stats['embedding_jobs_by_status'].get('failed', 0),
                'vector_search_available': embedded_messages > 0,
                'fts_search_available': True,  # Always available with PostgreSQL
                'hybrid_search_available': embedded_messages > 0
            }